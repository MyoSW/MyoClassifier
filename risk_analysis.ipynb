{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSHD Risk Analysis\n",
    "\n",
    "This notebook is meant to read, parse, create family trees and get data for each patient from the main FSHD Italian Registry.\n",
    "This is then used to train a network that can regress the probability that a new individual in the family tree shows sign of the disease given its existing family tree data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re as re\n",
    "import math as math\n",
    "from tabulate import tabulate\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score,roc_auc_score,make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input datasets\n",
    "\n",
    "This program reads in input family tree files exported in CSV format (comma separated values) by HaploPainter.\n",
    "It also fixes some typical problems before parsing a new file.\n",
    "By default, it searches for family trees in all subfolders of the `data` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_family_file(fileName):\n",
    "    lines = []\n",
    "    file_content = []\n",
    "    with open(fileName, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    with open(fileName, \"w\") as f:\n",
    "        for line in lines:\n",
    "            if \"PERSON\" not in line:\n",
    "                line = re.sub(r'(\\d+)(\\/\\d{2})', lambda x: x.group(1).zfill(4)+x.group(2), line )\n",
    "                f.write(line)\n",
    "                \n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_df = []\n",
    "\n",
    "print(\"Searching for family trees in the data folder\")\n",
    "for root, dirs, files in os.walk(\"data/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".utf8\"):\n",
    "            filePath = os.path.join(root, file)\n",
    "            fix_family_file(filePath)\n",
    "            family_df.append(pd.read_csv(filePath, header=None, usecols=[0,1,2,3], names=['FAMILY', 'PERSON','FATHER','MOTHER'], delimiter='\\t', index_col=1))\n",
    "            print(\"found family tree: \", filePath)\n",
    "print(len(family_df),\" family trees found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patients database is loaded here. Only the Excel Sheet `Tesi` is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(\"Now opening the patients database. This might take a while...\")\n",
    "\n",
    "# patients_df = pd.read_excel (r'data/dataset_tesi_finale_23012022.xlsx', sheet_name='Tesi', usecols=[0,1,5,6,7,8,9,10,13,18,38,39,40,685,686,687,688,689,690], index_col=0)\n",
    "# patients_df.columns = patients_df.columns.str.replace(' ', '_')\n",
    "# patients_df.columns = patients_df.columns.str.replace('_E2_C3_', '')\n",
    "# patients_df.columns = patients_df.columns.str.replace('_CCFf', '')\n",
    "# patients_df.dropna(subset=['FSHD_No_null','Ch4-1_no_null_validated','Date_of_Birth'], inplace=True)\n",
    "\n",
    "# patients_df[\"FACIALWEAKNESS\"] = pd.to_numeric(patients_df[\"FACIALWEAKNESS\"])\n",
    "# patients_df[\"SCAPGIRDLEINVOLV\"] = pd.to_numeric(patients_df[\"SCAPGIRDLEINVOLV\"])\n",
    "# patients_df[\"UPPERLIMBSINVOLV\"] = pd.to_numeric(patients_df[\"UPPERLIMBSINVOLV\"])\n",
    "# patients_df[\"LEGSINVOLVEMENT\"] = pd.to_numeric(patients_df[\"LEGSINVOLVEMENT\"])\n",
    "# patients_df[\"PELVGIRDLEINVOLV\"] = pd.to_numeric(patients_df[\"PELVGIRDLEINVOLV\"])\n",
    "# patients_df[\"ABDMUSCLEINVOLV\"] = pd.to_numeric(patients_df[\"ABDMUSCLEINVOLV\"])\n",
    "# patients_df[\"Date_of_Birth\"] = pd.to_datetime(patients_df[\"Date_of_Birth\"])\n",
    "\n",
    "# print(\"Database opened successfully.\")\n",
    "# patients_df['Classificazione_no_null'] = patients_df['Classificazione_no_null'].fillna(\"Z\")\n",
    "# patients_df.head()\n",
    "# print(\"Data from \", len(patients_df.index), \" patients loaded.\")\n",
    "\n",
    "# patients_df.columns = patients_df.columns.str.replace('Classificazione_no_null', 'clinical_category')\n",
    "# patients_df.columns = patients_df.columns.str.replace('ID_famiglia', 'family_id')\n",
    "# patients_df.columns = patients_df.columns.str.replace('Ch4-1_no_null_validated', 'allele_size_in_kb')\n",
    "# patients_df.columns = patients_df.columns.str.replace('FSHD_No_null', 'FSHD_score')\n",
    "\n",
    "\n",
    "# patients_df[\"Birth_Year\"] = pd.to_numeric(patients_df[\"Birth_Year\"])\n",
    "# patients_df[\"age_at_evaluation\"] = pd.to_numeric(patients_df[\"age_at_evaluation\"])\n",
    "# patients_df['age_at_evaluation'] = patients_df['age_at_evaluation'].fillna(-1)\n",
    "\n",
    "# patients_df[\"Year_at_evaluation\"] = pd.to_numeric(patients_df[\"Year_at_evaluation\"])\n",
    "\n",
    "# #print(patients_df.columns)\n",
    "# patients_df.to_hdf('patients_data.h5', key='df', mode='w')\n",
    "# #print(patients_df.dtypes)\n",
    "patients_df = pd.read_hdf('patients_data.h5')\n",
    "print(patients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDegreeOfKinship(dag, source, target):\n",
    "    distance = -1\n",
    "    # if source == target:\n",
    "    #     return 0\n",
    "    ancestor = nx.lowest_common_ancestor(dag,source, target, default=-1)\n",
    "    if ancestor != -1:\n",
    "        distance = nx.shortest_path_length(dag,ancestor,source) +nx.shortest_path_length(dag,ancestor,target)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir(\"family_graphs/\")\n",
    "training_df = pd.DataFrame(columns=['gender','DRA', 'age_at_evaluation','allele_length',\n",
    "                                    'severity', 'severity_binary', 'severity_from_score_binary', 'FSHD_score', 'category', \n",
    "                                    'max_score_1st_kinship', 'max_score_2nd_kinship', 'max_score_3rd_kinship', 'max_score_higher_kinship',\n",
    "                                    'max_facial_partial_score_1st_kinship', 'max_facial_partial_score_2nd_kinship', 'max_facial_partial_score_3rd_kinship', 'max_facial_partial_score_higher_kinship',\n",
    "                                    'max_scapular_girdle_partial_score_1st_kinship', 'max_scapular_girdle_partial_score_2nd_kinship', 'max_scapular_girdle_partial_score_3rd_kinship', 'max_scapular_girdle_partial_score_higher_kinship',\n",
    "                                    'max_upper_limbs_partial_score_1st_kinship', 'max_upper_limbs_partial_score_2nd_kinship', 'max_upper_limbs_partial_score_3rd_kinship', 'max_upper_limbs_partial_score_higher_kinship',\n",
    "                                    'max_legs_partial_score_1st_kinship', 'max_legs_partial_score_2nd_kinship', 'max_legs_partial_score_3rd_kinship', 'max_legs_partial_score_higher_kinship',\n",
    "                                    'max_pelvic_girdle_partial_score_1st_kinship', 'max_pelvic_girdle_partial_score_2nd_kinship', 'max_pelvic_girdle_partial_score_3rd_kinship', 'max_pelvic_girdle_partial_score_higher_kinship',\n",
    "                                    'max_abdomen_partial_score_1st_kinship', 'max_abdomen_partial_score_2nd_kinship', 'max_abdomen_partial_score_3rd_kinship', 'max_abdomen_partial_score_higher_kinship',])\n",
    "numberOfFamilies = 0\n",
    "maxIndividualsInFamily = 0\n",
    "allele_length = {}\n",
    "\n",
    "for df in family_df: \n",
    "    family = df[['FAMILY','FATHER','MOTHER']]\n",
    "    familyName = \"\"\n",
    "    personId=[]\n",
    "    fshd_score ={}\n",
    "    gender = {}\n",
    "    DRA = {}\n",
    "    clinical_category = {}\n",
    "    partial_scores = {}\n",
    "    age_at_evaluation = {}\n",
    "    for index, row in family.iterrows():\n",
    "        familyName = row['FAMILY']\n",
    "        if '/' in index and index in patients_df.index :\n",
    "            patients_row = patients_df.loc[index]\n",
    "            tmp_score = patients_row[\"FSHD_score\"]\n",
    "            tmp_allele_length = patients_row[\"allele_size_in_kb\"]\n",
    "            tmp_clinical_category = patients_row[\"clinical_category\"]\n",
    "            tmp_partial_scores = [patients_row[\"FACIALWEAKNESS\"],\n",
    "                                  patients_row[\"SCAPGIRDLEINVOLV\"],\n",
    "                                  patients_row[\"UPPERLIMBSINVOLV\"],\n",
    "                                  patients_row[\"LEGSINVOLVEMENT\"],\n",
    "                                  patients_row[\"PELVGIRDLEINVOLV\"],\n",
    "                                  patients_row[\"ABDMUSCLEINVOLV\"]]\n",
    "            if isinstance(tmp_score,float) and not math.isnan(tmp_score) and not math.isnan(tmp_allele_length) and tmp_clinical_category != \"Z\":\n",
    "                personId.append(index)\n",
    "                fshd_score[index] = tmp_score\n",
    "                gender[index] = patients_row[\"Sex\"]\n",
    "                DRA[index] = patients_row[\"DRA_(0=no;1=si)\"]\n",
    "                clinical_category[index] = tmp_clinical_category\n",
    "                allele_length[index] = tmp_allele_length\n",
    "                partial_scores[index] = tmp_partial_scores\n",
    "                print\n",
    "                if not math.isnan(patients_row[\"Year_at_evaluation\"]):\n",
    "                    age_at_evaluation[index] = patients_row[\"Year_at_evaluation\"] - patients_row[\"Date_of_Birth\"].year\n",
    "                else:\n",
    "                    age_at_evaluation[index] = 2021 - patients_row[\"Date_of_Birth\"].year\n",
    "                    \n",
    "    graph = nx.Graph()\n",
    "    dag = nx.DiGraph()\n",
    "    \n",
    "    print(\"\\n\\n\\nprocessing family\", familyName)\n",
    "    if len(personId) <2:\n",
    "        print(\"Family \", familyName, \" contains less than 2 people.\")\n",
    "        continue\n",
    "    numberOfFamilies = numberOfFamilies + 1\n",
    "\n",
    "    for index, row in family.iterrows():\n",
    "        if row['FATHER'] != \"0\" or row['MOTHER'] !=\"0\":\n",
    "            graph.add_edge(index,row['FATHER'])\n",
    "            graph.add_edge(index,row['MOTHER'])\n",
    "            dag.add_edge(row['FATHER'],index)\n",
    "            dag.add_edge(row['MOTHER'],index)\n",
    "    mates_list = []\n",
    "    for node in dag.nodes:\n",
    "        if dag.in_degree(node) == 0:\n",
    "            partners_list = []\n",
    "            for children in dag.successors(node):\n",
    "                for other_parent in dag.predecessors(children):\n",
    "                    if other_parent != node:\n",
    "                        partners_list.append(other_parent)\n",
    "            are_root_of_dag = True\n",
    "            for partner in partners_list:\n",
    "                are_root_of_dag &= (dag.in_degree(partner) == 0)\n",
    "            if not are_root_of_dag:\n",
    "                mates_list.append(node)\n",
    "\n",
    "\n",
    "    # mates_list = [node for node in list(nx.topological_sort(dag))[2:] if (dag.in_degree(node) == 0)]\n",
    "    mates_list_negatives = []\n",
    "    for node in mates_list:\n",
    "        if node in patients_df.index:\n",
    "            if math.isnan(fshd_score.get(node)) or not isinstance(fshd_score.get(node),float):\n",
    "                mates_list_negatives.append(node)\n",
    "            else:\n",
    "                if not (fshd_score.get(node) == 0 and DRA.get(node) == 0):\n",
    "                    mates_list_negatives.append(node)\n",
    "        else:\n",
    "            mates_list_negatives.append(node)\n",
    "    graph.remove_nodes_from(mates_list_negatives)\n",
    "    print(\"mates_list_negatives\",mates_list_negatives)\n",
    "\n",
    "    print(\"family\", familyName, \"contains\", len(personId),\"people\", personId)\n",
    "    peopleInFamily = 0\n",
    "    for pid in personId:\n",
    "        print(\"Creating dataset entry for person : \", pid, \"with fshd score \", fshd_score.get(pid))\n",
    "        if pid in mates_list_negatives:\n",
    "            # print(\"person\", pid, \"is a mate. Skipping.\")\n",
    "            continue\n",
    "        max_score_kinship = [-1,-1,-1,-1]\n",
    "        max_partial_scores_per_kinship = [[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1]]\n",
    "        peopleInFamily+=1\n",
    "        for index, row in family.iterrows():\n",
    "            if index in mates_list_negatives:\n",
    "                continue\n",
    "            if index != pid and (index in patients_df.index):\n",
    "                person_score = fshd_score.get(index)\n",
    "                if isinstance(person_score,float) and not math.isnan(person_score):\n",
    "                    # length = nx.shortest_path_length(graph,pid,index)\n",
    "                    length = calculateDegreeOfKinship(dag,pid,index)\n",
    "                    if length < 1:\n",
    "                        continue\n",
    "                    index_kinship = length - 1\n",
    "                    if index_kinship > 3:\n",
    "                        index_kinship = 3\n",
    "                    max_score_kinship[index_kinship] = max(max_score_kinship[index_kinship], person_score)\n",
    "                    for muscle_group_index in range(len(max_partial_scores_per_kinship[index_kinship])):\n",
    "                        tmp_partial_scores = partial_scores.get(index)\n",
    "                        max_partial_scores_per_kinship[index_kinship][muscle_group_index] = max(max_partial_scores_per_kinship[index_kinship][muscle_group_index], tmp_partial_scores[muscle_group_index])\n",
    "        print(pid, gender.get(pid), age_at_evaluation.get(pid), DRA.get(pid), allele_length.get(pid), fshd_score.get(pid), clinical_category.get(pid), max_score_kinship, max_partial_scores_per_kinship)\n",
    "        training_df = training_df.append({'gender': gender.get(pid),'age_at_evaluation': age_at_evaluation.get(pid),'DRA': DRA.get(pid), 'allele_length': allele_length.get(pid), \n",
    "                                 'FSHD_score' : fshd_score.get(pid), 'category':  clinical_category.get(pid),\n",
    "                                 'max_score_1st_kinship': max_score_kinship[0], 'max_score_2nd_kinship': max_score_kinship[1],\n",
    "                                 'max_score_3rd_kinship': max_score_kinship[2], 'max_score_higher_kinship': max_score_kinship[3],\n",
    "                                 'max_facial_partial_score_1st_kinship': max_partial_scores_per_kinship[0][0], 'max_facial_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][0], 'max_facial_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][0], 'max_facial_partial_score_higher_kinship': max_partial_scores_per_kinship[3][0],\n",
    "                                 'max_scapular_girdle_partial_score_1st_kinship': max_partial_scores_per_kinship[0][1], 'max_scapular_girdle_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][1], 'max_scapular_girdle_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][1], 'max_scapular_girdle_partial_score_higher_kinship': max_partial_scores_per_kinship[3][1],\n",
    "                                 'max_upper_limbs_partial_score_1st_kinship': max_partial_scores_per_kinship[0][2], 'max_upper_limbs_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][2], 'max_upper_limbs_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][2], 'max_upper_limbs_partial_score_higher_kinship': max_partial_scores_per_kinship[3][2],\n",
    "                                 'max_legs_partial_score_1st_kinship': max_partial_scores_per_kinship[0][3], 'max_legs_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][3], 'max_legs_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][3], 'max_legs_partial_score_higher_kinship': max_partial_scores_per_kinship[3][3],\n",
    "                                 'max_pelvic_girdle_partial_score_1st_kinship': max_partial_scores_per_kinship[0][4], 'max_pelvic_girdle_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][4], 'max_pelvic_girdle_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][4], 'max_pelvic_girdle_partial_score_higher_kinship': max_partial_scores_per_kinship[3][4],\n",
    "                                 'max_abdomen_partial_score_1st_kinship': max_partial_scores_per_kinship[0][5], 'max_abdomen_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][5], 'max_abdomen_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][5], 'max_abdomen_partial_score_higher_kinship': max_partial_scores_per_kinship[3][5]   }, ignore_index=True)\n",
    "    maxIndividualsInFamily = max(maxIndividualsInFamily, peopleInFamily)\n",
    "    print(graph)\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_facecolor('white')\n",
    "    # fig.suptitle(familyName)\n",
    "    # print(familyName)\n",
    "\n",
    "    options = {\n",
    "        \"font_size\": 18,\n",
    "        # \"node_size\": 3000,\n",
    "        \"node_color\": \"white\",\n",
    "        # \"node_color\":\"none\",\n",
    "        # \"edgecolors\": \"black\",\n",
    "        \"linewidths\": 2,\n",
    "        \"width\": 2,\n",
    "        \"bbox\":dict(facecolor='white', edgecolor='black', boxstyle='round,pad=1'),\n",
    "    }\n",
    "    pos = nx.spring_layout(graph,k=1.2, seed=1234)\n",
    "    nx.draw_networkx(graph, pos=pos, **options)\n",
    "    fig.savefig(\"family_graphs/\"+str(familyName)+\".pdf\")\n",
    "    fig.clf()\n",
    "\n",
    "\n",
    "print(\"Number of processed families: \", numberOfFamilies)\n",
    "\n",
    "print(\"Number of individuals\",training_df.shape[0])\n",
    "\n",
    "print(\"Largest family contains\", maxIndividualsInFamily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset preparation \n",
    "This is a final step before the actual training. We remove all the empty and nan values from the dataset, and make sure that numeric values are treated properly. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['gender'].replace('m','M', regex=True, inplace=True)\n",
    "training_df['gender'].replace('f','F', regex=True, inplace=True)\n",
    "training_df['gender'].replace('F','0', regex=True, inplace=True)\n",
    "training_df['gender'].replace('M','1', regex=True, inplace=True)\n",
    "training_df[\"gender\"] = pd.to_numeric(training_df[\"gender\"])\n",
    "def severity_from_score(row):\n",
    "    if row['FSHD_score'] >=3 :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "training_df[\"severity\"] = training_df['category'].replace([\"A\\d\",\"B\\d\", \"D\\d\", \"C\\d\"],[2,1,1,0],regex=True, inplace=False)\n",
    "training_df[\"severity_binary\"] = training_df['category'].replace([\"A\\d\",\"B\\d\", \"D\\d\", \"C\\d\"],[1,1,1,0],regex=True, inplace=False)\n",
    "training_df[\"severity_from_score_binary\"] = training_df.apply (lambda row: severity_from_score(row), axis=1)\n",
    "\n",
    "training_df[\"age_at_evaluation\"] = pd.to_numeric(training_df[\"age_at_evaluation\"])\n",
    "\n",
    "\n",
    "\n",
    "training_df[\"DRA\"] = pd.to_numeric(training_df[\"DRA\"])\n",
    "training_df[\"allele_length\"] = pd.to_numeric(training_df[\"allele_length\"])\n",
    "\n",
    "for k in training_df.columns:\n",
    "    if \"score\" in k:\n",
    "        training_df[k] = pd.to_numeric(training_df[k])\n",
    "\n",
    "print(training_df.category.unique())\n",
    "\n",
    "print(training_df.severity.unique())\n",
    "print(training_df.severity_binary.unique())\n",
    "print(\"training_df.severity_from_score_binary\", training_df.severity_from_score_binary.unique())\n",
    "print(\"training_df.age_at_evaluation\", training_df.age_at_evaluation.unique())\n",
    "\n",
    "print(training_df.category.unique())\n",
    "\n",
    "print(training_df.gender.unique())\n",
    "print(training_df.FSHD_score.unique())\n",
    "print(training_df.allele_length.unique())\n",
    "print(training_df.max_facial_partial_score_1st_kinship.unique())\n",
    "print(training_df.max_scapular_girdle_partial_score_1st_kinship.unique())\n",
    "print(training_df.max_upper_limbs_partial_score_1st_kinship.unique())\n",
    "print(training_df.max_legs_partial_score_1st_kinship.unique())\n",
    "print(training_df.max_pelvic_girdle_partial_score_1st_kinship.unique())\n",
    "print(training_df.max_abdomen_partial_score_1st_kinship.unique())\n",
    "\n",
    "print(training_df.max_score_1st_kinship.unique())\n",
    "\n",
    "print(training_df.columns)\n",
    "\n",
    "print(training_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data to HDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_hdf('training_data.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into independent and dependent variables\n",
    "We want to predict the FSHD score through all other variables. \n",
    "We will then use `X` to represent all the data used to make the classification, and `Y` to represent the FSHD score that we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_hdf('training_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_dataset.drop(['severity','severity_binary', 'severity_from_score_binary','FSHD_score','category',\n",
    " 'DRA',\n",
    " #'max_score_1st_kinship',\n",
    "#  'max_score_2nd_kinship',\n",
    " #'max_score_3rd_kinship', \n",
    " #'max_score_higher_kinship'\n",
    "    ], axis = 1).copy()\n",
    "X.head()\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=training_dataset['severity'].copy()\n",
    "y_binary=training_dataset['severity_binary'].copy()\n",
    "y_from_score_binary=training_dataset['severity_from_score_binary'].copy()\n",
    "\n",
    "y_from_score_binary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a preliminary XGBoost model\n",
    "We split the data into training and testing sets and build the model. Since data is imbalanced, we split using stratification .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=27, stratify=y)\n",
    "X_binary_train, X_binary_test, y_binary_train, y_binary_test = train_test_split(X, y_binary, random_state=27, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_xgb = xgb.XGBClassifier(objective='multi:softprob', missing=None, seed=42, num_class=3)\n",
    "# clf_xgb.fit(X_train,y_train,verbose=True,early_stopping_rounds=10,eval_metric='mlogloss', eval_set=[(X_test,y_test)])\n",
    "clf_xgb_binary = xgb.XGBClassifier(objective='binary:logistic', seed=42)\n",
    "clf_xgb_binary.fit(X_binary_train,y_binary_train,verbose=True,early_stopping_rounds=10,eval_metric='aucpr', eval_set=[(X_binary_test,y_binary_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_xgb_binary,X_binary_test,y_binary_test, normalize=\"true\",values_format='f',display_labels=[\"No symptom\",\"FSHD phenotype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='multi:softprob', seed=42, num_class=3)\n",
    "clf_xgb.fit(X_train,y_train,verbose=True,early_stopping_rounds=10,eval_metric='mlogloss', eval_set=[(X_test,y_test)])\n",
    "plot_confusion_matrix(clf_xgb,X_test,y_test, normalize=\"true\",values_format='f')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "This was executed and gave in output:\n",
    "```\n",
    "{'gamma': 0.25, 'learning_rate': 0.5, 'max_depth': 5, 'reg_lambda': 10.0, 'scale_pos_weight': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# param_grid = {\n",
    "#     'max_depth' : [3,4,5],\n",
    "#     'learning_rate': [0.1, 0.01, 0.05, 0.5, 1],\n",
    "#     'gamma': [0, 0.25, 1.0],\n",
    "#     'reg_lambda' : [0., 1., 10., 20., 100.],\n",
    "#     'scale_pos_weight' : [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# optimal_params = GridSearchCV(\n",
    "#     estimator = clf_xgb_binary, \n",
    "#     param_grid = param_grid,\n",
    "#     scoring = 'roc_auc', \n",
    "#     verbose = 2,\n",
    "#     n_jobs=4, \n",
    "#     cv =3\n",
    "# )\n",
    "\n",
    "# optimal_params.fit(X_binary_train,y_binary_train, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=[(X_binary_test,y_binary_test)], verbose=False)\n",
    "# print(optimal_params.best_params_)\n",
    "# {'gamma': 0.25, 'learning_rate': 0.5, 'max_depth': 5, 'reg_lambda': 10.0, 'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_binary_optimized = xgb.XGBClassifier(objective='binary:logistic',gamma=0.25, learning_rate=0.5, max_depth=5, reg_lambda=10, scale_pos_weight=1, seed=42,)\n",
    "clf_xgb_binary_optimized.fit(X_binary_train,y_binary_train, eval_set=[(X_binary_test,y_binary_test)])\n",
    "clf_xgb_binary_optimized.save_model(\"fshd_binary_risk_analysis.json\")\n",
    "plot_confusion_matrix(clf_xgb_binary_optimized,X_binary_test,y_binary_test, normalize=\"true\",values_format='f',display_labels=[\"No symptom\",\"FSHD phenotype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst = clf_xgb_binary_optimized.get_booster()\n",
    "# for importance_type in ('weight', 'gain', 'cover', 'total_gain', 'total_cover'):\n",
    "#     print(\"%s: \" % importance_type, bst.get_score(importance_type=importance_type))\n",
    "\n",
    "# node_params = {'shape': 'box', 'style': 'filled, rounded', 'fillcolor': '#78cbe'}\n",
    "# leaf_params = {'shape': 'box', 'style': 'filled', 'fillcolor': '#e48038'}\n",
    "\n",
    "# graph_data=xgb.to_graphviz(clf_xgb_binary_optimized,num_trees=0,size=\"10,10\",condition_node_params=node_params,leaf_node_params=leaf_params)\n",
    "# graph_data.view(filename='xgb_tree_fshd_binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf_xgb_binary_optimized.predict_proba(X_binary_test)\n",
    "preds = y_preds[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_binary_test, preds)\n",
    "auc_score = auc(fpr, tpr)\n",
    "plt.clf()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12.5, 8.5)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# it's helpful to add a diagonal to indicate where chance \n",
    "# scores lie (i.e. just flipping a coin)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1.005])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "fig.savefig('roc_binary.pdf', dpi=100)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import interp\n",
    "labels_predictions = {}\n",
    "classifiers = {}\n",
    "\n",
    "predictions = [y_from_score_binary,y_binary]\n",
    "labels_classes = [['FSHD score $\\leq 2$','FSHD score $> 2$'],['no phenotype','myopathic\\nphenotype']]\n",
    "labels_predictions[0] = \"y_from_score_binary\"\n",
    "labels_predictions[1] = \"y_binary\"\n",
    "thresholds_predictions=[0.3,0.50]\n",
    "label_index = 0\n",
    "for prediction in predictions:\n",
    "    n_splits = 20\n",
    "    clf_xgb_binary_optimized_cv = xgb.XGBClassifier(objective='binary:logistic',gamma=0.25, learning_rate=0.5, max_depth=8, reg_lambda=10, scale_pos_weight=1, seed=42,num_parallel_tree = 10, use_label_encoder =False,eval_metric ='auc',  missing=-1)\n",
    "    kfold = StratifiedKFold(n_splits=n_splits,shuffle=True, random_state=1)\n",
    "    results = cross_val_score(clf_xgb_binary_optimized_cv, X, prediction, cv=kfold)\n",
    "    print(results)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    confusion_matrix_cv_array = []\n",
    "    confusion_matrix_cv_normalized_array = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    i = 0\n",
    "    for fold_index, (train_index,val_index) in enumerate(kfold.split(X, prediction)):\n",
    "        print('Batch {} started...'.format(fold_index))\n",
    "        bst_cv = clf_xgb_binary_optimized_cv.fit(X.loc[train_index,:],prediction.loc[train_index],\n",
    "                eval_set = [(X.loc[val_index,:],prediction.loc[val_index])],\n",
    "                early_stopping_rounds=10,\n",
    "                verbose= 200, \n",
    "                eval_metric ='auc'\n",
    "                )\n",
    "        probas_ = clf_xgb_binary_optimized_cv.predict_proba(X.loc[val_index,:])\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(prediction.loc[val_index], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        # plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                #  label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        confusion_matrix_cv_array.append(confusion_matrix(prediction.loc[val_index], \n",
    "                                        clf_xgb_binary_optimized_cv.predict_proba(X.loc[val_index,:])[:,1]>=thresholds_predictions[label_index], normalize=None))\n",
    "        confusion_matrix_cv_normalized_array.append(confusion_matrix(prediction.loc[val_index], \n",
    "                                        clf_xgb_binary_optimized_cv.predict_proba(X.loc[val_index,:])[:,1]>=thresholds_predictions[label_index], normalize=\"true\"))\n",
    "        i += 1\n",
    "\n",
    "    # y_preds = clf_xgb_binary_optimized_cv.predict_proba(X_binary_test)\n",
    "    # preds = y_preds[:,1]\n",
    "    # fpr, tpr, _ = roc_curve(prediction_test, preds)\n",
    "    # auc_score = auc(fpr, tpr)\n",
    "    # plt.clf()\n",
    "    # fig = plt.gcf()\n",
    "    # fig.set_size_inches(12.5, 8.5)\n",
    "\n",
    "    # plt.title('ROC Curve')\n",
    "    # plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "    # # it's helpful to add a diagonal to indicate where chance \n",
    "    # # scores lie (i.e. just flipping a coin)\n",
    "    # plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "    # plt.xlim([0,1])\n",
    "    # plt.ylim([0,1.005])\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "\n",
    "    # plt.legend(loc='lower right')\n",
    "    # plt.show()\n",
    "    # fig.savefig('roc.pdf', dpi=100)\n",
    "    print(confusion_matrix_cv_array)\n",
    "\n",
    "\n",
    "    cm_final  = [[0., 0.],[0., 0.]]\n",
    "\n",
    "    cm_final_normalized  = [[0., 0.],[0., 0.]]\n",
    "\n",
    "    for c in confusion_matrix_cv_array:\n",
    "        cm_final = cm_final + c\n",
    "\n",
    "\n",
    "    for c in confusion_matrix_cv_normalized_array:\n",
    "        cm_final_normalized = cm_final_normalized + c\n",
    "\n",
    "    cm_final_normalized = cm_final_normalized/n_splits\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = cm_final.ravel()\n",
    "\n",
    "    y_line_threshold = tp/(tp+fn)\n",
    "    x_line_threshold = fp/(fp+tn)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    plt.clf()\n",
    "    fig = plt.gcf()\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    plt.plot([x_line_threshold,x_line_threshold], [0,1], linestyle='dotted', lw=2, color='black',\n",
    "            label=\"Threshold: \"+str(thresholds_predictions[label_index]*100)+\"%\", alpha=.8)\n",
    "\n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate',fontsize=18)\n",
    "    plt.ylabel('True Positive Rate',fontsize=18)\n",
    "    plt.title('Cross-Validation ROC',fontsize=18)\n",
    "    plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    fig.savefig('roc_'+ labels_predictions[label_index]+'.pdf', dpi=100)\n",
    "    model_fname = \"fshd_binary_risk_analysis_cv_\" + labels_predictions[label_index]+\".json\"\n",
    "    clf_xgb_binary_optimized_cv.save_model(model_fname)\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    fig.clf()\n",
    "\n",
    "    \n",
    "\n",
    "    xgb.plot_importance(clf_xgb_binary_optimized_cv, max_num_features=10)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_dpi(100)\n",
    "    fig.set_size_inches(10,4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    fig.savefig('features_importance_'+ labels_predictions[label_index]+'.pdf', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    plt.clf()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_final)\n",
    "\n",
    "    # NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
    "    # disp = disp.plot()\n",
    "    disp.display_labels = labels_classes[label_index]\n",
    "    disp.plot(values_format = '.5g')\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(\"confusion_matrix_\"+labels_predictions[label_index]+\".pdf\", dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    fig.clf()\n",
    "\n",
    "    disp_normalized = ConfusionMatrixDisplay(confusion_matrix=cm_final_normalized)\n",
    "    disp_normalized.display_labels = labels_classes[label_index]\n",
    "    disp_normalized.plot(values_format = '.5g')\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    \n",
    "\n",
    "    fig.savefig(\"confusion_matrix_normalized_\"+labels_predictions[label_index]+\".pdf\", dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    bst = clf_xgb_binary_optimized_cv.get_booster()\n",
    "    for importance_type in ('weight', 'gain', 'cover', 'total_gain', 'total_cover'):\n",
    "        print(\"%s: \" % importance_type, bst.get_score(importance_type=importance_type))\n",
    "\n",
    "    node_params = {'shape': 'box', 'style': 'filled, rounded', 'fillcolor': '#78cbe'}\n",
    "    leaf_params = {'shape': 'box', 'style': 'filled', 'fillcolor': '#e48038'}\n",
    "\n",
    "    graph_data=xgb.to_graphviz(clf_xgb_binary_optimized_cv,num_trees=0,size=\"10,10\",condition_node_params=node_params,leaf_node_params=leaf_params)\n",
    "    graph_data.view(filename='xgb_tree_fshd_binary_'+ labels_predictions[label_index])\n",
    "    classifiers[labels_predictions[label_index]] = clf_xgb_binary_optimized_cv\n",
    "\n",
    "    label_index+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of a new family \n",
    "\n",
    "Store the haplopainter csv file in the `input` folder of the new family. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(columns=X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "dag = nx.DiGraph()\n",
    "\n",
    "def generatePredictionFromPersonId(target_personId=\"-1\"):\n",
    "\n",
    "\n",
    "    input_family_df = []\n",
    "\n",
    "    print(\"Searching for family trees in the input folder in csv format with utf8 extension\")\n",
    "    for root, dirs, files in os.walk(\"input/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".utf8\"):\n",
    "                filePath = os.path.join(root, file)\n",
    "                fix_family_file(filePath)\n",
    "                input_family_df.append(pd.read_csv(filePath, header=None, usecols=[0,1,2,3], names=['FAMILY', 'PERSON','FATHER','MOTHER'], delimiter='\\t', index_col=1))\n",
    "                print(\"found family tree: \", filePath)\n",
    "    print(len(input_family_df),\" family trees found\")\n",
    "    if len(input_family_df) == 0:\n",
    "        sys.exit(\"No family found in folder.\")\n",
    "    if len(input_family_df) > 1:\n",
    "        sys.exit(\"More than one family found in folder. Please remove the unnecessary families from input folder.\")\n",
    "\n",
    "    if target_personId == \"-1\":\n",
    "        target_personId = input(\"Insert the person id in the tree: \")\n",
    "\n",
    "\n",
    "    new_prediction_df = pd.DataFrame(columns=X.columns)\n",
    "    target_DRA = 0\n",
    "    target_allele_length = 0\n",
    "    target_gender = \"m\"\n",
    "    print(\"Checking whether \", target_personId, \"is already in registry\")\n",
    "    if target_personId in patients_df.index:\n",
    "        target_DRA = patients_df.get(\"DRA_(0=no;1=si)\").get(target_personId)\n",
    "        target_allele_length = patients_df.get(\"allele_size_in_kb\").get(target_personId)\n",
    "        target_gender = patients_df.get(\"Sex\").get(target_personId)\n",
    "        print(\"Person \", target_personId, \" found in registry\")\n",
    "    else:\n",
    "        print(target_personId, \"is not in registry (or its data are incomplete). You need to feed data manually\")\n",
    "        while True:\n",
    "            target_DRA = input(\"Insert 1 if person has DRA, or 0 if not: \")\n",
    "            if target_DRA not in (\"0\", \"1\"):\n",
    "                print(\"Not an appropriate choice.\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "            target_allele_length = input(\"Insert the allele length in kb: \")\n",
    "            if isinstance(target_allele_length,int):\n",
    "                print(\"Please insert an integer number.\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        while True:\n",
    "            target_gender = input(\"Insert the gender (f, m): \")\n",
    "            if target_gender not in (\"m\", \"f\", \"M\", \"F\"):\n",
    "                print(\"Not an appropriate choice.\")\n",
    "            else:\n",
    "                break\n",
    "    print(\"DRA: \", target_DRA)\n",
    "    print(\"Allele length: \", target_allele_length,\"kb\")\n",
    "    print(\"Gender: \", target_gender)\n",
    "\n",
    "\n",
    "    for df in input_family_df: \n",
    "        family = df[['FAMILY','FATHER','MOTHER']]\n",
    "        familyName = \"\"\n",
    "        personId=[]\n",
    "        personId.append(target_personId)\n",
    "        fshd_score ={}\n",
    "        gender = {}\n",
    "        DRA = {}\n",
    "        clinical_category = {}\n",
    "        allele_length = {}\n",
    "        partial_scores = {}\n",
    "        for index, row in family.iterrows():\n",
    "            familyName = row['FAMILY']\n",
    "            if '/' in index and index in patients_df.index:\n",
    "                tmp_score = patients_df.get(\"FSHD_score\").get(index)\n",
    "                tmp_allele_length = patients_df.get(\"allele_size_in_kb\").get(index)\n",
    "                tmp_clinical_category = patients_df.get(\"clinical_category\").get(index)\n",
    "                tmp_partial_scores = [patients_df.get(\"FACIALWEAKNESS\").get(index),\n",
    "                                    patients_df.get(\"SCAPGIRDLEINVOLV\").get(index),\n",
    "                                    patients_df.get(\"UPPERLIMBSINVOLV\").get(index),\n",
    "                                    patients_df.get(\"LEGSINVOLVEMENT\").get(index),\n",
    "                                    patients_df.get(\"PELVGIRDLEINVOLV\").get(index),\n",
    "                                    patients_df.get(\"ABDMUSCLEINVOLV\").get(index)]\n",
    "                if index != target_personId and isinstance(tmp_score,float) and not math.isnan(tmp_score) and not math.isnan(tmp_allele_length) and tmp_clinical_category != \"Z\":\n",
    "                    # personId.append(index)\n",
    "                    fshd_score[index] = tmp_score\n",
    "                    gender[index] = patients_df.get(\"Sex\").get(index)\n",
    "                    DRA[index] = patients_df.get(\"DRA_(0=no;1=si)\").get(index)\n",
    "                    clinical_category[index] = tmp_clinical_category\n",
    "                    allele_length[index] = tmp_allele_length\n",
    "                    partial_scores[index] = tmp_partial_scores\n",
    "\n",
    "\n",
    "\n",
    "        for index, row in family.iterrows():\n",
    "            if row['FATHER'] != \"0\" or row['MOTHER'] !=\"0\":\n",
    "                graph.add_edge(index,row['FATHER'])\n",
    "                graph.add_edge(index,row['MOTHER'])\n",
    "                dag.add_edge(row['FATHER'],index)\n",
    "                dag.add_edge(row['MOTHER'],index)\n",
    "        mates_list = []\n",
    "        for node in dag.nodes:\n",
    "            if dag.in_degree(node) == 0:\n",
    "                partners_list = []\n",
    "                for children in dag.successors(node):\n",
    "                    for other_parent in dag.predecessors(children):\n",
    "                        if other_parent != node:\n",
    "                            partners_list.append(other_parent)\n",
    "                are_root_of_dag = True\n",
    "                for partner in partners_list:\n",
    "                    are_root_of_dag &= (dag.in_degree(partner) == 0)\n",
    "                if not are_root_of_dag:\n",
    "                    mates_list.append(node)\n",
    "\n",
    "\n",
    "        # mates_list = [node for node in list(nx.topological_sort(dag))[2:] if (dag.in_degree(node) == 0)]\n",
    "        mates_list_negatives = []\n",
    "        for node in mates_list:\n",
    "            if node in patients_df.index:\n",
    "                if math.isnan(fshd_score.get(node)) or not isinstance(fshd_score.get(node),float):\n",
    "                    mates_list_negatives.append(node)\n",
    "                else:\n",
    "                    if not (fshd_score.get(node) == 0 and DRA.get(node) == 0):\n",
    "                        mates_list_negatives.append(node)\n",
    "            else:\n",
    "                mates_list_negatives.append(node)\n",
    "        graph.remove_nodes_from(mates_list_negatives)\n",
    "\n",
    "        for pid in personId:\n",
    "            print(\"Creating dataset entry for person : \", pid, \"with fshd score \", fshd_score.get(pid))\n",
    "            if pid in mates_list_negatives:\n",
    "                # print(\"person\", pid, \"is a mate. Skipping.\")\n",
    "                continue\n",
    "            # print(tabulate(patients_df.loc[[pid]],headers='keys', tablefmt='psql'))\n",
    "            max_score_kinship = [-1,-1,-1,-1]\n",
    "            max_partial_scores_per_kinship = [[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1,-1]]\n",
    "            for index, row in family.iterrows():\n",
    "                if index in mates_list_negatives:\n",
    "                    continue\n",
    "                if index != pid and (index in patients_df.index):\n",
    "                    person_score = fshd_score.get(index)\n",
    "                    if isinstance(person_score,float) and not math.isnan(person_score):\n",
    "                        # length = nx.shortest_path_length(graph,pid,index)\n",
    "                        length = calculateDegreeOfKinship(dag,pid,index)\n",
    "                        if length < 1:\n",
    "                            continue\n",
    "                        index_kinship = length - 1\n",
    "                        if index_kinship > 3:\n",
    "                            index_kinship = 3\n",
    "                        max_score_kinship[index_kinship] = max(max_score_kinship[index_kinship], person_score)\n",
    "                        for muscle_group_index in range(len(max_partial_scores_per_kinship[index_kinship])):\n",
    "                            tmp_partial_scores = partial_scores.get(index)\n",
    "                            max_partial_scores_per_kinship[index_kinship][muscle_group_index] = max(max_partial_scores_per_kinship[index_kinship][muscle_group_index], tmp_partial_scores[muscle_group_index])\n",
    "\n",
    "\n",
    "            new_prediction_df = new_prediction_df.append({'gender': target_gender,\n",
    "                                    # 'DRA': target_DRA, \n",
    "                                    'allele_length': target_allele_length,\n",
    "                                    # 'age_at_evaluation': age_at_evaluation[pid],\n",
    "                                    'max_score_1st_kinship': max_score_kinship[0], 'max_score_2nd_kinship': max_score_kinship[1], 'max_score_3rd_kinship': max_score_kinship[2], 'max_score_higher_kinship': max_score_kinship[3],\n",
    "                                    \n",
    "                                    'max_facial_partial_score_1st_kinship': max_partial_scores_per_kinship[0][0], 'max_facial_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][0], 'max_facial_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][0], 'max_facial_partial_score_higher_kinship': max_partial_scores_per_kinship[3][0],\n",
    "                                    'max_scapular_girdle_partial_score_1st_kinship': max_partial_scores_per_kinship[0][1], 'max_scapular_girdle_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][1], 'max_scapular_girdle_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][1], 'max_scapular_girdle_partial_score_higher_kinship': max_partial_scores_per_kinship[3][1],\n",
    "                                    'max_upper_limbs_partial_score_1st_kinship': max_partial_scores_per_kinship[0][2], 'max_upper_limbs_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][2], 'max_upper_limbs_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][2], 'max_upper_limbs_partial_score_higher_kinship': max_partial_scores_per_kinship[3][2],\n",
    "                                    'max_legs_partial_score_1st_kinship': max_partial_scores_per_kinship[0][3], 'max_legs_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][3], 'max_legs_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][3], 'max_legs_partial_score_higher_kinship': max_partial_scores_per_kinship[3][3],\n",
    "                                    'max_pelvic_girdle_partial_score_1st_kinship': max_partial_scores_per_kinship[0][4], 'max_pelvic_girdle_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][4], 'max_pelvic_girdle_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][4], 'max_pelvic_girdle_partial_score_higher_kinship': max_partial_scores_per_kinship[3][4],\n",
    "                                    'max_abdomen_partial_score_1st_kinship': max_partial_scores_per_kinship[0][5], 'max_abdomen_partial_score_2nd_kinship': max_partial_scores_per_kinship[1][5], 'max_abdomen_partial_score_3rd_kinship': max_partial_scores_per_kinship[2][5], 'max_abdomen_partial_score_higher_kinship': max_partial_scores_per_kinship[3][5]\n",
    "                                    \n",
    "            },ignore_index=True)\n",
    "\n",
    "        # print(graph.graph)\n",
    "        # fig = plt.figure(figsize=(16,10))\n",
    "        # ax = fig.add_subplot(1, 1, 1)\n",
    "        # ax.set_facecolor('white')\n",
    "        # fig.suptitle(familyName)\n",
    "        # # print(familyName)\n",
    "\n",
    "        # options = {\n",
    "        #     \"font_size\": 18,\n",
    "        #     \"node_size\": 2000,\n",
    "        #     \"node_color\": \"white\",\n",
    "            \n",
    "        #     \"edgecolors\": \"black\",\n",
    "        #     \"linewidths\": 2,\n",
    "        #     \"width\": 2,\n",
    "        # }\n",
    "        # nx.draw_networkx(graph, pos=nx.spring_layout(graph,k=1.2), **options)\n",
    "\n",
    "\n",
    "    new_prediction_df['gender'].replace(['m','M'],[1,1], regex=True, inplace=True)\n",
    "    new_prediction_df['gender'].replace(['f','F'],[0,0], regex=True, inplace=True)\n",
    "    for k in new_prediction_df.columns:\n",
    "        new_prediction_df[k] = pd.to_numeric(new_prediction_df[k])\n",
    "    return new_prediction_df.copy(),  target_personId, target_allele_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query, target_personId, target_allele_length = generatePredictionFromPersonId()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.nodes)\n",
    "print(dag.nodes)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_facecolor('white')\n",
    "fig.suptitle(familyName)\n",
    "# print(familyName)\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 18,\n",
    "    # \"node_size\": 3000,\n",
    "    \"node_color\": \"white\",\n",
    "    # \"node_color\":\"none\",\n",
    "    # \"edgecolors\": \"black\",\n",
    "    # \"linewidths\": 2,\n",
    "    \"width\": 2,\n",
    "    \"bbox\":dict(facecolor=\"white\",alpha=0.2,edgecolor='black', boxstyle='round,pad=1'),\n",
    "    \"arrows\":True,\n",
    "    \"arrowsize\":10, \n",
    "    \"arrowstyle\":'-|>',\n",
    "}\n",
    "pos = nx.spring_layout(dag,k=1.2, seed=1234)\n",
    "nx.draw_networkx(dag, pos=pos, **options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iteration = classifiers['y_binary'].get_booster().best_iteration\n",
    "print(\"computing for \",target_personId)\n",
    "avg_result = 0\n",
    "ages = [30]\n",
    "for age in ages:\n",
    "    query.iloc[0,query.columns.get_loc('age_at_evaluation')] = age\n",
    "    result = classifiers['y_binary'].predict_proba(query,iteration_range=(0, best_iteration))[0][1]\n",
    "    print(result*100,\"%\")\n",
    "    avg_result += result\n",
    "    # print(query)\n",
    "\n",
    "avg_result /= len(ages)\n",
    "print(\"The probability that \", target_personId, \"with allele length of\", target_allele_length, \"kb \\nwill show the phenotype is \", \"{:.1f}\".format(avg_result*100),\"%\")\n",
    "if avg_result > 0.5:\n",
    "    print(\"Subject classified as myopathic phenotype\")\n",
    "else:\n",
    "    print(\"Subject classified as non-myopathic phenotype\")\n",
    "if target_personId in patients_df.index:\n",
    "    print(patients_df.loc[target_personId])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in dag.nodes:\n",
    "    if \"/\" in person and person in patients_df.index:\n",
    "        query, target_personId, target_allele_length = generatePredictionFromPersonId(person)\n",
    "        best_iteration = classifiers['y_binary'].get_booster().best_iteration\n",
    "        print(\"computing for \",target_personId)\n",
    "        avg_result = 0\n",
    "        ages = [30]\n",
    "        for age in ages:\n",
    "            query.iloc[0,query.columns.get_loc('age_at_evaluation')] = age\n",
    "            result = classifiers['y_binary'].predict_proba(query,iteration_range=(0, best_iteration))[0][1]\n",
    "            # print(result*100,\"%\")\n",
    "            avg_result += result\n",
    "            # with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            #     print(query)\n",
    "\n",
    "        avg_result /= len(ages)\n",
    "        print(\"The probability that \", target_personId, \"with allele length of\", target_allele_length, \"kb \\nwill show the phenotype is \", \"{:.1f}\".format(avg_result*100),\"%\")\n",
    "        if avg_result > 0.5:\n",
    "            print(\"Subject classified as myopathic phenotype\")\n",
    "        else:\n",
    "            print(\"Subject classified as non-myopathic phenotype\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
